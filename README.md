## Итоговый проект по курсу DevOps Netology a148ru

### Назначение

Проект выполнен в рамках дипломного практикума Yandex.Cloud при прохождении курса DevOps-инженер [образовательной платформы Нетология](https://netology.ru)

### Цели проекта

- Подготовить облачную инфраструктуру на базе облачного провайдера Яндекс.Облако.
- Запустить и сконфигурировать Kubernetes кластер.
- Установить и настроить систему мониторинга.
- Настроить и автоматизировать сборку тестового приложения с использованием Docker-контейнеров.
- Настроить CI для автоматической сборки и тестирования.
- Настроить CD для автоматического развёртывания приложения.

### Зависимости и инструменты

Для развертывания проекта:
1. Следующие программы должны быть установлены и сконфигурированы:
- [terraform версии 1.9.X](https://developer.hashicorp.com/terraform/install)
- [yc cli](https://yandex.cloud/ru/docs/cli/operations/install-cli)
- [kubectl](https://kubernetes.io/ru/docs/tasks/tools/install-kubectl/)
- [git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)

2. Должно быть зарегистрировано облако в Yandex.Cloud и создан каталог в облаке для проекта.
3. Проект придусматривает, что у вас есть сервисный  аккаунт с авторизованными ключами и с необходимыми правами, для создания других сервисных аккаунтов и назначения им прав на каталог облака.

### Запуск проекта

Клонировать проект с помощью git

$ `git clone https://github.com/a148ru/netology-devops-project.git`

Перейти в каталог проекта и запустить скрипт с необходимыми параметрами

```
$ cd netology-dev-project
$ ./terraform-deploy.sh -a <authorized_key in json> -c <cloud_id> -f <folder_id>`
```
где:
- `<authorized_key in json>` - путь к файлу с авторизованными ключами административного сервисного аккаунта
- `<cloud_id>` - ID облака Yandex.Cloud
- `<folder_id>` - ID каталога в облаке Yandex.Cloud


------------------------------------

## Описание выполнения проекта


Проект состоит из трех частей, две предварительные и одна основная.

1. **Предварительные**:
- подготовка сервисного аккаунта с минимально необходимыми правами для выполнения основной части по созданию инфраструктуры
- создание бакета для хранения стейта основной инфраструктуры

2. **Основная**:
- развертывание основной инфраструктуры



#### Процесс выполнения 

![Alt text](./img/diag.svg)

1. Скрипт `terraform-deploy.sh` проверяет переменные окружения:

```
$TF_VAR_auth_file     # полный путь к файлу с авторизованными ключами
$TF_VAR_cloud_id      # id облака
$TF_VAR_folder_id     # id каталога в облаке
```
>[!NOTE]
>Если переменные на заданы, при запуске скрипта, необходимо передать значения параметров с соответствующими ключами.

2. Создается сервисный аккаунт с седующими правами на каталог:
- `editor`
- `k8s.clusters.agent`
- `vpc.publicAdmin`
- `container-registry.admin`

и ключи, статический ключ доступа для бакета и авторизованный для дальнейшей работы с инфраструктурой и кластером.
В результате будут созданы три файла 
- `.env` в корне проекта, содержащем переменные окружения
  * `TF_VAR_sa_id`
  * `TF_VAR_static_id_key`
  * `TF_VAR_static_access_key`
  * `TF_VAR_static_secret_key`
- `sa_key.json` - содержащий авторизованный ключ для созданного сервисного аккаунта
- `personal.auto.tfvars` с данными для работы terraform в каталоге bucket

3. Создается бакет с случайным постфиксом в имени и сервисному аккаунту, созданному на прошлом шаге назначаются права `storage.editor` на созданный бакет. В файл .env добавляется переменная окружения с именем бакета `TF_VAR_storage_id`. Создается  файл `personal.auto.tfvars` в каталоге infra с неодходимыми параметрами для дальнейшей работы terraform при создании инфраструктуры.

4. Создание регионального кластера Kubernetes с использованием *Yandex Managed Service for Kubernetes*, создание группы узлов (Node Group) и группы безопасности (Security Group, SG). Создается файл конфигурации для работы `kubectl`. Создание хранилища образов docker - *Yandex Container Registry*

5. Разворачивается ситема мониторинга на основе пакета [kube-prometheus](https://github.com/prometheus-operator/kube-prometheus), с доступом к Grafana по 80 порту сетевого балансировщика нагрузки ([Network Load Balancer, NLB](https://yandex.cloud/ru/docs/network-load-balancer/concepts/)).

6. Клонирование тестового приложения, сборка docker-образа, публикация образа в подготовленное хранилище и деплой приложения в кластер Kubernetes с доступом к по 80 порту сетевого балансировщика нагрузки.

#### CI/CD

В качестве CI/CD системы был использован GitHub Action

1. Инфраструктура
Pipeline настроен на работу при любом коммите в основную ветку main. Для корректной работы, должны быть заданы следующие переменные окружения (Enviroment secrets):
```
SSH_KEY                     # ssh ключ для подключения к нодам 
TF_VAR_CLOUD_ID             # id облака
TF_VAR_FOLDER_ID            # id каталога в облаке
TF_VAR_REGION               # регион, обычно ru-central1
TF_VAR_SA_ID                # id сервисного аккаунта
TF_VAR_STATIC_ID_KEY        # id статического ключа сервисного аккаунта
TF_VAR_STATIC_ACCESS_KEY    # идентификатор статического ключ сервисного аккаунта
TF_VAR_STATIC_SECRET_KEY    # секретный ключ статического ключа сервисного аккаунта
TF_VAR_STORAGE_ID           # имя бакета, где расположен стейт terraform
YC_TOKEN                    # авторизованный ключ сервисного аккаунта
```


2. Тестовое приложение
Для [тестового приложения](https://github.com/a148ru/app_demo/tree/main/.github/workflows) используются два pipeline, файлы [commit.yml](https://github.com/a148ru/app_demo/blob/main/.github/workflows/commit.yml) и [deploy.yml](https://github.com/a148ru/app_demo/blob/main/.github/workflows/deploy.yml). Соответственно первый выполняет сборку и публикацию образа при коммите в основную ветку main, второй работает при создании нового тега и релиза приложения, собирая и публикуя образ, выполняет его деплой в кластер Kubernetes.
Для корректной работы pipeline, должны быть заданы следующие переменные окружения:
```
K8S_ID                      # id кластера в сервисе Yandex Managed Service for Kubernetes
KUBECONFIG_DATA             # файл конфигурации kubectl в base64
YC_SA_KEY                   # авторизованный ключ сервисного аккаунта с правами на хранилище Yandex Container Registry и кластер  Yandex Managed Service
```



## Отчет по выполнению работы

Отчет о выполнении работы с снимками экрана в файле [REPORT.md](./REPORT.md)